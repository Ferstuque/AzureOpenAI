EN
# Azure Open AI - Features

This repository contains information about the main features of Azure Open AI, including LLMs, models, tokenization, and more.

## LLMs (Large Language Models) ğŸ’¡

**LLMs (Large Language Models)** are deep learning models trained with large volumes of text to generate, understand, and process human language.

LLMs are the key component behind text generation. In a nutshell, they consist of large pretrained transformer models trained to predict the next word (or more precisely, the next token) based on input text. Since they predict one token at a time, more elaborate processes are needed to generate new sentences beyond simply calling the model â€” **autoregressive generation** is required.

- **What are they?** They are neural networks that can perform a wide range of tasks, such as translation, text generation, summarization, etc.
- **In a nutshell:** They "learn" from large datasets and apply that knowledge to a variety of language tasks.

Learn more: [LLM Tutorial on Hugging Face](https://huggingface.co/docs/transformers/llm_tutorial)

## Open AI Tokenization ğŸ”‘

**Tokenization** is the process of splitting text into smaller units called *tokens*. These tokens can be words, parts of words, or even individual characters. OpenAI uses tokenization to efficiently understand and process text.

## Playground ğŸ› ï¸

The **OpenAI Playground** provides an interactive interface to test language models with various parameters. Some key options are:

### Temperature ğŸŒ¡ï¸
- **What is it?** It controls the randomness of the generated responses.
  - **Temperature 0 to 1**: More deterministic or more creative responses.

### Top P ğŸ¯
- **What is it?** An alternative method to control randomness, using a probabilistic approach to choose words.
  - **Top P from 0.1 to 0.9**: The cumulative probability of selected words.

### Max Tokens ğŸ§‘â€ğŸ’»
- **What is it?** Limits the number of tokens generated in a response.

### Penalties âš–ï¸
- **Frequency Penalty**: Reduces excessive repetition of words.
- **Presence Penalty**: Penalizes the repetition of already used terms, increasing response diversity.

### Message System ğŸ’¬
- **What is it?** Allows interaction with the model in a sequence of messages, useful for creating conversations or more contextual prompts.

### Prompt Engineering ğŸ“
- **What is it?** The art of structuring prompts in a way that helps the model better understand what is being asked.

## Open AI Models ğŸ§ 

OpenAI offers several models for different purposes:

- **GPT-3 (gpt-3.5, gpt-3.5-turbo)**: General-purpose language models.
- **GPT-4**: The most advanced version with greater comprehension and generation capabilities.
- **GPT-1 Mini**: A compact and optimized version of GPT-1.
- **GPT-4 Turbo**: An optimized version of GPT-4, offering faster performance and reduced costs.
- **DALL-E**: A model for generating images from text descriptions.

### CLI (Command Line Interface) ğŸ’»
- OpenAI offers command-line interface support, making it easier to automate tasks.

### File Upload with Azure Storage Account ğŸ“‚
- Use **Azure Blob Storage** to upload and process large volumes of data, such as text files or other content that needs to be analyzed by the model.

## System Message ğŸ› ï¸

The **System Message** is a special type of message that defines the model's behavior in a conversation. It can be used to guide how the model responds.

### Types of Responses:
- **Zero-shot**: The model responds without prior training or preparation on the subject.
- **Direct response**: The model answers directly to the prompt, without relying on additional context.
- **Based on the prompt only**: The model uses only the information provided in the prompt.

## How Response Formulation Works ğŸ§‘â€ğŸ’»

Model responses are formulated considering:
- **Max Response**: The model can generate a complete response up to the defined token limit.
- **Previous Messages**: When using multiple interactions, previous messages may be included to provide context and improve response coherence.

## Temperature vs. Top-P âš–ï¸

These two parameters help control the creativity and diversity of the responses.

### Temperature:
- **Temperature 0**: More deterministic, predictable, and direct responses.
- **Temperature 1**: More random, creative, and varied responses.

### Top-P:
- Controls the cumulative probability of chosen words.
- **Top-P from 0.1 to 0.9**: The model selects words whose cumulative probability reaches the *p* value.

**Tip:** Use **Top P** or **Temperature**, rarely both, as both affect the level of randomness.

## Frequency Penalty vs. Presence Penalty ğŸ”

- **Frequency Penalty**: Penalizes the repetition of frequently used words.
- **Presence Penalty**: Penalizes the repetition of words that have already appeared, helping to increase response diversity.

## How to Create Good Images Using DALL-E ğŸ–¼ï¸

When using the **DALL-E** model to generate images, keep the following tips in mind:

### Tips for good images:
- **Clarity**: Be clear and direct in describing what you want in the image.
- **Specificity**: The more details, the better the image quality.
- **Context**: Include any necessary context to bring your description to life.
- **Structure**: Organize your ideas logically and coherently to make image creation easier.

---

I hope this guide helps you understand the features and how to use them effectively! ğŸš€

---

PT-BR
# Azure Open AI - Funcionalidades

Este repositÃ³rio contÃ©m informaÃ§Ãµes sobre as principais funcionalidades do Azure Open AI, incluindo LLMs, modelos, tokenizaÃ§Ã£o, e mais.

## LLMs (Large Language Models) ğŸ’¡

Os **LLMs** (Large Language Models) sÃ£o modelos de aprendizado profundo treinados com grandes volumes de texto para gerar, entender e processar linguagem humana. 

LLMs sÃ£o a peÃ§a chave por trÃ¡s da geraÃ§Ã£o de texto. Em resumo, eles consistem em grandes modelos transformer prÃ©-treinados, treinados para prever a prÃ³xima palavra (ou, mais precisamente, o prÃ³ximo token) com base em um texto de entrada. Como eles predizem um token por vez, Ã© necessÃ¡rio realizar um processo mais elaborado para gerar novas frases, em vez de apenas chamar o modelo â€” Ã© necessÃ¡rio usar a geraÃ§Ã£o autorregressiva.

- **O que sÃ£o?** SÃ£o redes neurais que podem realizar uma ampla gama de tarefas, como traduÃ§Ã£o, geraÃ§Ã£o de texto, resumo, etc.
- **Em poucas palavras:** Eles podem "aprender" a partir de grandes conjuntos de dados e aplicar esse conhecimento a uma infinidade de tarefas linguÃ­sticas.

Saiba mais: [LLM Tutorial na Hugging Face](https://huggingface.co/docs/transformers/llm_tutorial)

## TokenizaÃ§Ã£o da Open AI ğŸ”‘

A **tokenizaÃ§Ã£o** Ã© o processo de dividir texto em unidades menores chamadas *tokens*. Estes tokens podem ser palavras, partes de palavras ou atÃ© mesmo caracteres individuais. A OpenAI usa tokenizaÃ§Ã£o para entender e processar o texto de maneira eficiente.

## Playground ğŸ› ï¸

O **Playground** da OpenAI oferece uma interface interativa para testar modelos de linguagem com diversos parÃ¢metros. Algumas das principais opÃ§Ãµes sÃ£o:

### Temperatura ğŸŒ¡ï¸
- **O que Ã©?** Controla a aleatoriedade nas respostas geradas. 
  - **Temperatura 0**: Respostas mais determinÃ­sticas.
  - **Temperatura 1**: Respostas mais criativas e variadas.

### Top P ğŸ¯
- **O que Ã©?** Um mÃ©todo alternativo ao controle de temperatura, usando uma abordagem probabilÃ­stica para escolher as palavras.
  - **Top P de 0.1 a 0.9**: A probabilidade acumulada de palavras escolhidas pelo modelo.

### Tokens MÃ¡ximos ğŸ§‘â€ğŸ’»
- **O que Ã©?** Limita o nÃºmero de tokens gerados em uma resposta.

### Penalidades âš–ï¸
- **Penalidade de FrequÃªncia**: Reduz a repetiÃ§Ã£o excessiva de palavras.
- **Penalidade de PresenÃ§a**: Penaliza a repetiÃ§Ã£o de termos jÃ¡ usados, aumentando a diversidade da resposta.

### Sistema de Mensagens ğŸ’¬
- **O que Ã©?** Permite interagir com o modelo em uma sequÃªncia de mensagens. Ãštil para criar conversas ou prompts mais contextuais.
  
### Engenharia de Prompt ğŸ“
- **O que Ã©?** A arte de estruturar os prompts de forma que o modelo entenda melhor o que Ã© solicitado.

## Modelos Open AI ğŸ§ 

A OpenAI oferece diversos modelos para diferentes finalidades:

- **GPT-3 (gpt-3.5, gpt-3.5-turbo)**: Modelos de linguagem geral.
- **GPT-4**: A versÃ£o mais avanÃ§ada, com maior capacidade de compreensÃ£o e geraÃ§Ã£o.
- **GPT-1 Mini**: Uma versÃ£o compacta e otimizada do GPT-1.
- **GPT-4 Turbo**: VersÃ£o otimizada do GPT-4, com maior velocidade e custos reduzidos.
- **DALL-E**: Modelo para geraÃ§Ã£o de imagens a partir de descriÃ§Ãµes de texto.

### CLI (Interface de Linha de Comando) ğŸ’»
- A OpenAI oferece suporte para interaÃ§Ã£o atravÃ©s de linha de comando, facilitando a automaÃ§Ã£o de tarefas.

### Upload de Arquivos com Azure Storage Account ğŸ“‚
- Use **Blob Storage** do Azure para carregar e processar grandes volumes de dados, como arquivos de texto ou outros conteÃºdos que precisam ser analisados pelo modelo.

## System Message ğŸ› ï¸

O **System Message** Ã© um tipo especial de mensagem que define o comportamento do modelo em uma conversa. Ele pode ser usado para guiar como o modelo responde.

### Tipos de Respostas:
- **Zero-shot**: O modelo responde sem ter sido treinado ou preparado previamente sobre o assunto.
- **Resposta direta**: O modelo responde diretamente ao prompt, sem depender de contexto adicional.
- **Baseada apenas no prompt**: O modelo utiliza apenas a informaÃ§Ã£o fornecida no prompt.

## Como funciona a FormulaÃ§Ã£o de Respostas ğŸ§‘â€ğŸ’»

As respostas do modelo sÃ£o formadas levando em consideraÃ§Ã£o:
- **Resposta MÃ¡xima**: O modelo pode gerar uma resposta completa atÃ© o limite de tokens definidos.
- **Mensagens Anteriores**: Quando se utiliza mÃºltiplas interaÃ§Ãµes, as mensagens anteriores podem ser incluÃ­das para fornecer contexto e melhorar a coerÃªncia das respostas.

## Temperatura vs. Top-P âš–ï¸

Esses dois parÃ¢metros ajudam a controlar a criatividade e a diversidade das respostas.

### Temperatura:
- **Temperatura 0**: Mais determinista, respostas mais previsÃ­veis e diretas.
- **Temperatura 1**: Mais aleatÃ³ria, respostas mais criativas e variadas.

### Top-P:
- Controla a probabilidade cumulativa de palavras sendo escolhidas.
- **Top-P de 0.1 a 0.9**: O modelo escolhe palavras com uma probabilidade acumulada que atinge o valor de *p*.

**Dica:** Use **Top P** ou **Temperatura**, raramente ambos, pois ambos afetam o nÃ­vel de aleatoriedade.

## Frequency Penalty vs. Presence Penalty ğŸ”

- **Frequency Penalty**: Penaliza a repetiÃ§Ã£o de palavras frequentemente usadas.
- **Presence Penalty**: Penaliza a repetiÃ§Ã£o de palavras jÃ¡ mencionadas, ajudando a aumentar a diversidade das respostas.

## Como Criar Boas Imagens com o DALL-E ğŸ–¼ï¸

Quando utilizar o modelo **DALL-E** para gerar imagens, tenha em mente as seguintes dicas:

### Dicas para boas imagens:
- **Clareza**: Seja claro e direto ao descrever o que deseja na imagem.
- **Especificidade**: Quanto mais detalhes, melhor serÃ¡ a qualidade da imagem gerada.
- **Contexto**: Inclua o contexto necessÃ¡rio para dar vida Ã  sua descriÃ§Ã£o.
- **Estrutura**: Organize suas ideias de forma lÃ³gica e coerente para facilitar a criaÃ§Ã£o da imagem.

---

Espero que esse guia ajude a entender as funcionalidades e como usÃ¡-las de forma eficaz! ğŸš€
